groups:
 - name: alert-rules
   rules:

   - alert: PrometheusDown
     expr: up{job="prometheus"} == 0
     for: 30s 
     labels:
       severity: critical
       team_type: monitoring

   - alert: NodeExporterDown
     expr: up{job="node"} == 0
     for: 30s
     labels:
       severity: critical
       team_type: infra
     annotations:
       summary: 'Node Expoter is Down!'
       description: 'instance: {{ $labels.instance }} | job: {{ $labels.job }}'
       app_link: 'http://localhost:9100'

   - record: job:node_memory_Mem_bytes:available
     expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100

   - alert: NodeMemoryUsageAbove40%
     expr: 40 < (100 - job:node_memory_Mem_bytes:available) < 75
     for: 2m
     labels:
       severity: warning
       team_type: infra
     annotations:
       summary: 'Node memory usage is going high'
       description: 'instance: {{ $labels.instance }} | job: {{ $labels.job }} | value: {{ $value }}% '
  
   - alert: NodeMemoryUsageAbove75%
     expr: (100 - job:node_memory_Mem_bytes:available) > 75
     for: 2m
     labels:
       severity: critical
       team_type: infra
     annotations:
       summary: 'Node memory usage is going high'
       description: 'instance: {{ $labels.instance }} | job: {{ $labels.job }} | value: {{ $value }}% '